{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1571137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdb025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"D:/Masters/Research/DataCoSupplyChainDataset.csv\", encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a96e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df = df.drop(columns=['shipping date (DateOrders)','Date1'])\n",
    "\n",
    "# df = df.drop(columns=[\"Path\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9566a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2=df.tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef9d532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days for shipping (real)</th>\n",
       "      <th>Days for shipment (scheduled)</th>\n",
       "      <th>Customer City</th>\n",
       "      <th>Customer Zipcode</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Order City</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>725.0</td>\n",
       "      <td>18.279451</td>\n",
       "      <td>-66.037064</td>\n",
       "      <td>Bikaner</td>\n",
       "      <td>18-01-2018</td>\n",
       "      <td>12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>95125.0</td>\n",
       "      <td>37.292233</td>\n",
       "      <td>-121.881279</td>\n",
       "      <td>Bikaner</td>\n",
       "      <td>17-01-2018</td>\n",
       "      <td>12:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90027.0</td>\n",
       "      <td>34.125946</td>\n",
       "      <td>-118.291016</td>\n",
       "      <td>Townsville</td>\n",
       "      <td>16-01-2018</td>\n",
       "      <td>11:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>725.0</td>\n",
       "      <td>18.253769</td>\n",
       "      <td>-66.037048</td>\n",
       "      <td>Townsville</td>\n",
       "      <td>15-01-2018</td>\n",
       "      <td>11:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Tonawanda</td>\n",
       "      <td>14150.0</td>\n",
       "      <td>43.013969</td>\n",
       "      <td>-78.879066</td>\n",
       "      <td>Toowoomba</td>\n",
       "      <td>19-01-2018</td>\n",
       "      <td>11:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108958</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11207.0</td>\n",
       "      <td>40.640930</td>\n",
       "      <td>-73.942711</td>\n",
       "      <td>Shanghái</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>03:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108959</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>93304.0</td>\n",
       "      <td>35.362545</td>\n",
       "      <td>-119.018700</td>\n",
       "      <td>Hirakata</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108960</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>41.629959</td>\n",
       "      <td>-72.967155</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108961</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>725.0</td>\n",
       "      <td>18.213350</td>\n",
       "      <td>-66.370575</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108962</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>725.0</td>\n",
       "      <td>18.290380</td>\n",
       "      <td>-66.370613</td>\n",
       "      <td>Nagercoil</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>18:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108963 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Days for shipping (real)  Days for shipment (scheduled) Customer City  \\\n",
       "0                              5                              4        Caguas   \n",
       "1                              4                              4      San Jose   \n",
       "2                              3                              4   Los Angeles   \n",
       "3                              2                              4        Caguas   \n",
       "4                              6                              4     Tonawanda   \n",
       "...                          ...                            ...           ...   \n",
       "108958                         4                              4      Brooklyn   \n",
       "108959                         3                              2   Bakersfield   \n",
       "108960                         5                              4       Bristol   \n",
       "108961                         3                              4        Caguas   \n",
       "108962                         4                              4        Caguas   \n",
       "\n",
       "        Customer Zipcode   Latitude   Longitude  Order City        Date   Time  \n",
       "0                  725.0  18.279451  -66.037064     Bikaner  18-01-2018  12:27  \n",
       "1                95125.0  37.292233 -121.881279     Bikaner  17-01-2018  12:06  \n",
       "2                90027.0  34.125946 -118.291016  Townsville  16-01-2018  11:45  \n",
       "3                  725.0  18.253769  -66.037048  Townsville  15-01-2018  11:24  \n",
       "4                14150.0  43.013969  -78.879066   Toowoomba  19-01-2018  11:03  \n",
       "...                  ...        ...         ...         ...         ...    ...  \n",
       "108958           11207.0  40.640930  -73.942711    Shanghái  2016-01-20  03:40  \n",
       "108959           93304.0  35.362545 -119.018700    Hirakata  2016-01-19  01:34  \n",
       "108960            6010.0  41.629959  -72.967155    Adelaide  2016-01-20  21:00  \n",
       "108961             725.0  18.213350  -66.370575    Adelaide  2016-01-18  20:18  \n",
       "108962             725.0  18.290380  -66.370613   Nagercoil  2016-01-19  18:54  \n",
       "\n",
       "[108963 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "125ab987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"D:/Masters/Research/file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b3656a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108963 entries, 0 to 108962\n",
      "Data columns (total 9 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   Days for shipping (real)       108963 non-null  int64  \n",
      " 1   Days for shipment (scheduled)  108963 non-null  int64  \n",
      " 2   Customer City                  108963 non-null  object \n",
      " 3   Customer Zipcode               108961 non-null  float64\n",
      " 4   Latitude                       108963 non-null  float64\n",
      " 5   Longitude                      108963 non-null  float64\n",
      " 6   Order City                     108963 non-null  object \n",
      " 7   Date                           108963 non-null  object \n",
      " 8   Time                           108963 non-null  object \n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744a77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feeeb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from geopy.distance import geodesic\n",
    "from opencage.geocoder import OpenCageGeocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0f21375",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENCAGE_API_KEY = '53cea7afa5ea42a99f235b750b22a19d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324b380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoder = OpenCageGeocode(OPENCAGE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98dea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(city):\n",
    "    result = geocoder.geocode(city)\n",
    "    if result and len(result):\n",
    "        return result[0]['geometry']['lat'], result[0]['geometry']['lng']\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c51bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bikaner', 'Townsville', 'Toowoomba', ..., 'Morganton', 'CA',\n",
       "       'Sumner'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cities = pd.concat([df['Order City'], df['Customer City']]).unique()\n",
    "unique_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94003974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store coordinates of cities\n",
    "city_coords = {}\n",
    "for city in unique_cities:\n",
    "    lat, lon = get_coordinates(city)\n",
    "    if lat is not None and lon is not None:\n",
    "        city_coords[city] = (lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc38609",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "cords=pd.DataFrame(city_coords).T\n",
    "cords[\"Place\"]=cords.index\n",
    "cords.to_csv(\"D:/Masters/Research/cords.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cords=pd.read_csv(\"D:/Masters/Research/cords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac93f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of city names and their coordinates\n",
    "city_names = list(city_coords.keys())\n",
    "coords = np.array(list(city_coords.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "# Use NearestNeighbors to find the nearest N cities for each city\n",
    "N = 5  # Number of nearest neighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=N, algorithm='ball_tree').fit(coords)\n",
    "distances, indices = nbrs.kneighbors(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce358e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph of cities with distances as weights\n",
    "G = nx.Graph()\n",
    "for i, city in enumerate(city_names):\n",
    "    for j in range(1, N):  # Skip the first one because it's the city itself\n",
    "        neighbor_city = city_names[indices[i][j]]\n",
    "        distance = geodesic(city_coords[city], city_coords[neighbor_city]).miles\n",
    "        G.add_edge(city, neighbor_city, weight=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the shortest path of cities\n",
    "def find_path(order_city, customer_city):\n",
    "    if order_city not in city_coords or customer_city not in city_coords:\n",
    "        return None\n",
    "    try:\n",
    "        path = nx.shortest_path(G, source=order_city, target=customer_city, weight='weight')\n",
    "        return ' -> '.join(path)\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the path to the dataset\n",
    "df['Path'] = df.apply(lambda row: find_path(row['Order City'], row['Customer City']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Path.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e8278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d8ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the Path column into separate columns\n",
    "path_columns = df2['Path'].str.split(' -> ', expand=True)\n",
    "\n",
    "\n",
    "path_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df2 is your main DataFrame and path_columns is the DataFrame you want to save inside df2\n",
    "df2[\"Path2\"] = [pd.DataFrame(path_columns.iloc[i].dropna()) for i in range(len(path_columns))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81726073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f000d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.Path2.iloc[1].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/Miami/2015-01-11/2015-01-16?key=XER7B2RE72KSTRX2DXA2867WF\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the response was successful\n",
    "if response.status_code == 200:\n",
    "    # Print the response content (assuming it is JSON)\n",
    "    try:\n",
    "        data = response.json()  # Parse the response as JSON\n",
    "        print(data)  # Print the parsed data\n",
    "    except ValueError:\n",
    "        print(\"Error: Response content is not in JSON format\")\n",
    "else:\n",
    "    print(f\"Error: Received response with status code {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_weather_data(\"Cork\",\"2015-01-16\",\"2015-01-17\")\n",
    "fetch_weather_data(df2['Path2'].iloc[1].iloc[2].item(), histo_dat[1]['Start Date'], histo_dat[1]['End Date'])\n",
    "# l=df2['Path2'].iloc[1].iloc[1]\n",
    "# k=l.item()\n",
    "# k\n",
    "\n",
    "# df2['Path2'].iloc[1].iloc[2].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Path2'].iloc[1].iloc[2], histo_dat[1]['Start Date'], histo_dat[1]['End Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676670c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to fetch weather data\n",
    "def fetch_weather_data(city, start_date, end_date):\n",
    "    api_key = \"FBEMAY2RDDD3646FG2AXZ55WV\"\n",
    "    url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{city}/{start_date}/{end_date}?key={api_key}&include=days\"\n",
    "    response = requests.get(url)\n",
    "    # Check if the response was successful\n",
    "    if response.status_code == 200:\n",
    "    # Print the response content (assuming it is JSON)\n",
    "        try:\n",
    "            data = response.json()  # Parse the response as JSON\n",
    "            return(pd.DataFrame(data[\"days\"]))  # Print the parsed data\n",
    "        except ValueError:\n",
    "            print(\"Error: Response content is not in JSON format\")\n",
    "    else:\n",
    "        print(f\"Error: Received response with status code {response.status_code}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# Prepare date ranges and fetch weather data\n",
    "histo_dat = []\n",
    "for index, row in df2.iterrows():\n",
    "    date_str = row['Date']\n",
    "    try:\n",
    "        date_obj = datetime.strptime(date_str, '%d-%m-%Y')\n",
    "        start_date = (date_obj - timedelta(days=5)).strftime('%Y-%m-%d')\n",
    "        end_date = date_obj.strftime('%Y-%m-%d')\n",
    "        histo_dat.append({\n",
    "                'Start Date': start_date,\n",
    "                'End Date': end_date,\n",
    "            })\n",
    "    except ValueError:\n",
    "        # Skip rows with invalid date format\n",
    "        continue\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e21a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# Prepare date ranges and fetch weather data\n",
    "forecast_date = []\n",
    "for index, row in df2.iterrows():\n",
    "    date_str = row['Date']\n",
    "    try:\n",
    "        date_obj = datetime.strptime(date_str, '%d-%m-%Y')\n",
    "        start_date = date_obj.strftime('%Y-%m-%d')\n",
    "        end_date = (date_obj + timedelta(days=row[\"Days for shipping (real)\"])).strftime('%Y-%m-%d')\n",
    "        forecast_date.append({\n",
    "                'Start Date': start_date,\n",
    "                'End Date': end_date,\n",
    "            })\n",
    "    except ValueError:\n",
    "        # Skip rows with invalid date format\n",
    "        continue\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histo_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733236cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "import pandas as pd\n",
    "\n",
    "def forecast_weather(city, start_date_hist, end_date_hist, start_date_forecast, end_date_forecast):\n",
    "    # Fetch historical weather data\n",
    "    df_hist = fetch_weather_data(city, start_date_hist, end_date_hist)\n",
    "    \n",
    "    if df_hist is None:\n",
    "        print(\"Failed to fetch historical weather data\")\n",
    "        return None\n",
    "\n",
    "    # Filter out constant columns from df_hist\n",
    "    df_hist_filtered = df_hist.loc[:, (df_hist != df_hist.iloc[0]).any()]\n",
    "\n",
    "    # Ensure numeric data types\n",
    "    df_hist_filtered = df_hist_filtered.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Check for NaN values and handle them appropriately (fill with mean, median, or dropna)\n",
    "    df_hist_filtered = df_hist_filtered.dropna()\n",
    "\n",
    "    # Check if there's sufficient data\n",
    "    if len(df_hist_filtered) < 5:  # Adjust this number based on your data requirements\n",
    "        print(\"Insufficient data for VAR model fitting\")\n",
    "        return df_hist_filtered\n",
    "\n",
    "    # Fit the VAR model\n",
    "    try:\n",
    "        model = VAR(df_hist_filtered)\n",
    "        model_fit = model.fit(maxlags=3)  # Adjust maxlags as needed\n",
    "\n",
    "        # Forecast\n",
    "        forecast_steps = (end_date_forecast - start_date_forecast).days + 1\n",
    "        forecast = model_fit.forecast(df_hist_filtered.values[-model_fit.k_ar:], steps=forecast_steps)\n",
    "\n",
    "        # Create a DataFrame for the forecast\n",
    "        forecast_df = pd.DataFrame(forecast, index=pd.date_range(start=start_date_forecast, periods=forecast_steps, closed='right'), columns=df_hist_filtered.columns)\n",
    "\n",
    "        # Print the forecast (optional)\n",
    "        print(forecast_df)\n",
    "\n",
    "        return forecast_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting VAR model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "forecast_weather(\"cork\", \"2015-05-10\", \"2015-06-10\", \"2015-06-11\", \"2015-06-12\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47721340",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=fetch_weather_data(\"cork\", \"2015-06-05\", \"2015-06-10\")\n",
    "df_hist_filtered = l.loc[:, (l != l.iloc[0]).any()]\n",
    "# df_hist_filtered = df_hist_filtered.apply(pd.to_numeric, errors='coerce')\n",
    "# df_hist_filtered = df_hist_filtered.dropna()\n",
    "# df_hist_filtered.isna().sum()\n",
    "df_hist_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Collect results in a list\n",
    "results = []\n",
    "\n",
    "# Assuming df2, histo_dat, and forecast_date are defined and structured appropriately\n",
    "for i, path in enumerate(df2['Path2']):\n",
    "    city_forecast = {}\n",
    "    for city in path:\n",
    "        forecast_df = forecast_weather(city, histo_dat[i]['Start Date'], histo_dat[i]['End Date'], forecast_date[i]['Start Date'], forecast_date[i]['End Date'])\n",
    "        if forecast_df is not None:\n",
    "            city_forecast[city] = forecast_df\n",
    "    results.append(city_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Path2.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a383c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_dat[1]['Start Date'], histo_dat[1]['End Date'], forecast_date[1]['Start Date'], forecast_date[1]['End Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Path2'].iloc[1].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "dtta = pd.DataFrame(k['days'][0]['hours'])\n",
    "\n",
    "dtta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e625477",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847b460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
